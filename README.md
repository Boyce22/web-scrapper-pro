# WebScrapper Pro

**Web Image Scraper & Bulk Downloader**

Ferramenta CLI profissional para extraÃ§Ã£o e download em massa de imagens de pÃ¡ginas web. Combina scraping avanÃ§ado com Puppeteer e downloads paralelos otimizados com connection pooling.

## ğŸš€ CaracterÃ­sticas

- **Dual Approach**: Modo automÃ¡tico e manual para diferentes tipos de proteÃ§Ã£o
- **High Performance**: Downloads concorrentes com controle de paralelismo
- **Cloudflare Support**: NavegaÃ§Ã£o manual para bypass de proteÃ§Ãµes
- **Network Monitoring**: Captura de imagens em tempo real via traffic analysis
- **Professional Logging**: Sistema de logs estruturado para debugging e monitoramento

## ğŸ“¦ InstalaÃ§Ã£o

```bash
npm install
```

## ğŸ›  Uso

```bash
npm start
```

### Fluxo de InteraÃ§Ã£o

1. **Selecionar Abordagem**:

   - `AutomÃ¡tica`: Para sites sem proteÃ§Ã£o (scraping tradicional)
   - `Manual`: Para Cloudflare e sites com proteÃ§Ã£o avanÃ§ada

2. **Configurar ParÃ¢metros**:

   - URL alvo
   - Modo headless (com/sem interface)
   - NÃºmero de downloads simultÃ¢neos

3. **ExecuÃ§Ã£o**:
   - Modo automÃ¡tico: Extrai e baixa imagens automaticamente
   - Modo manual: Permite interaÃ§Ã£o humana para resolver CAPTCHAs

## ğŸ— Arquitetura

### Estrutura de Projeto

```
src/
â”œâ”€â”€ downloader/
â”‚   â”œâ”€â”€ fast-downloader.js      # Download concorrente de URLs
â”‚   â”œâ”€â”€ network-downloader.js   # Captura via network monitoring
â”‚   â””â”€â”€ image-extractor.js      # ExtraÃ§Ã£o de URLs de imagens
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.js               # Sistema de logging
â”‚   â”œâ”€â”€ config.js               # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ scroll.js               # Utilidades de scroll
â”‚   â””â”€â”€ common.js               # FunÃ§Ãµes utilitÃ¡rias
â””â”€â”€ scraper.js                  # Classe principal
```

### Componentes Principais

#### WebScraper

Classe principal que orquestra o processo de scraping

#### FastImageDownloader

- Downloads concorrentes com `p-limit`
- Controle de rate limiting
- Retry automÃ¡tico e tratamento de erros
- EstatÃ­sticas de performance

#### NetworkImageDownloader

- Monitoramento de responses HTTP em tempo real
- Captura de imagens via network traffic
- GeraÃ§Ã£o de nomes de arquivo Ãºnicos
- Salvamento em lote

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```javascript
// utils/config.js
export const CONFIG = {
  OUTPUT_DIR: './downloads',
  TIMEOUT: 30000,
  MAX_CONCURRENT: 100,
  REQUEST_HEADERS: {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
  },
};
```

### ParÃ¢metros de Performance

- **Concurrent Downloads**: 1-200 (default: CPU cores Ã— 25)
- **Timeout**: 30 segundos
- **Retry Attempts**: AutomÃ¡tico via Axios
- **Keep-Alive**: ConexÃµes HTTP reutilizÃ¡veis

## ğŸ“Š Logging

Sistema estruturado com mÃºltiplos nÃ­veis:

```javascript
logger.info('Iniciando scraping', { url, approach });
logger.debug('Configurando interceptaÃ§Ã£o');
logger.warn('Nenhuma imagem encontrada');
logger.error('Falha no processo', { error: message });
```

## ğŸ›¡ Tratamento de Erros

- **Unhandled Rejections**: Captura e log de promises nÃ£o tratadas
- **Uncaught Exceptions**: Tratamento global de exceÃ§Ãµes
- **Network Errors**: Retry automÃ¡tico e fallback
- **File System**: ValidaÃ§Ã£o de permissÃµes e espaÃ§o

## ğŸš¨ Casos de Uso

### Sites com Cloudflare

```
Approach: Manual
Headless: false
InteraÃ§Ã£o: Resolver CAPTCHA manualmente
```

### Sites Sem ProteÃ§Ã£o

```
Approach: AutomÃ¡tica
Headless: true
Downloads: 50-100 concorrentes
```

### Performance CrÃ­tica

```
Approach: AutomÃ¡tica
Headless: true
Downloads: 200 concorrentes
```

## ğŸ”§ Desenvolvimento

### Adicionar Novo Extrator

```javascript
// downloader/custom-extractor.js
export class CustomImageExtractor {
  async extract(page, url) {
    // Implementar lÃ³gica customizada
    return imageUrls;
  }
}
```

### Extender Logging

```javascript
import logger from './utils/logger.js';

logger.addContext({ module: 'custom-module' });
```

## ğŸ“ˆ Performance

- **Velocidade**: AtÃ© 200 downloads simultÃ¢neos
- **MemÃ³ria**: Otimizado com stream processing
- **Rede**: Connection pooling e keep-alive
- **Disco**: Escrita assÃ­ncrona e batch operations

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork do projeto
2. Branch feature (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push branch (`git push origin feature/AmazingFeature`)
5. Abrir Pull Request

## âš ï¸ Disclaimer

Esta ferramenta Ã© destinada para:

- Aprendizado e pesquisa
- Download de conteÃºdo pÃºblico
- AutomaÃ§Ã£o de workflows legÃ­timos

Respeite:

- Termos de serviÃ§o de websites
- Direitos autorais
- Rate limiting e politeness policies

## ğŸ“„ LicenÃ§a

DistribuÃ­do sob licenÃ§a MIT. Veja `LICENSE` para mais informaÃ§Ãµes.

---

**Nota**: Sempre verifique a legalidade do scraping em cada website antes de usar esta ferramenta.
